{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPG/TmdLdIet3CwD+9y5VqT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BabeRush/NLP_final_project/blob/main/training_untagged.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training - untagged data"
      ],
      "metadata": {
        "id": "Wb80KGrq4u2h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notebook preparation"
      ],
      "metadata": {
        "id": "S5o-iTkq4zLE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configurations"
      ],
      "metadata": {
        "id": "DWmudSpX6gv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking high RAM from google\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atwulLF86qMV",
        "outputId": "af159acf-25dd-4846-eab4-1c0d1c8619d8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning and checking for GPU usage\n",
        "import torch\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "DEVICE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IOrLnY3k8GbP",
        "outputId": "1edd72ba-9448-491e-fcd9-3270d1e8cee4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "jIx1EQ6r8bxf"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports & Installations"
      ],
      "metadata": {
        "id": "quzhpRQ769E7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZxRBMFD4x9w",
        "outputId": "b38f6796-306d-4220-98b2-83580fd46d87"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.32.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTS\n",
        "# General\n",
        "import warnings\n",
        "import random\n",
        "import sys\n",
        "\n",
        "# Math & Data organization\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Deep Learning\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast , BertForSequenceClassification\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AdamW\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Visualization\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from tabulate import tabulate\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Working with files\n",
        "from google.colab import files\n",
        "import pickle\n",
        "import shutil"
      ],
      "metadata": {
        "id": "Wb8Yc_8S5Be7"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the datasets"
      ],
      "metadata": {
        "id": "FHXGntwn8tNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/BabeRush/NLP_final_project.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlwd4QMX8zJ7",
        "outputId": "19a8850b-052d-485c-8ac3-198e0d1612af"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NLP_final_project'...\n",
            "remote: Enumerating objects: 106, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 106 (delta 9), reused 14 (delta 4), pack-reused 76\u001b[K\n",
            "Receiving objects: 100% (106/106), 118.87 MiB | 12.01 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n",
            "Updating files: 100% (21/21), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zO4nciHCTX1c",
        "outputId": "cb790fe0-8436-4118-fd9a-2712e57dfdaf"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get the processed datasets"
      ],
      "metadata": {
        "id": "keMewjkF-GeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_ISOT_train = pd.read_pickle('/content/NLP_final_project/FN-classification/Datasets_Processes/Train/X_ISOT_train.pkl')\n",
        "X_LIAR_train = pd.read_pickle('/content/NLP_final_project/FN-classification/Datasets_Processes/Train/X_LIAR_train.pkl')\n",
        "y_ISOT_train = pd.read_pickle('/content/NLP_final_project/FN-classification/Datasets_Processes/Train/y_ISOT_train.pkl')\n",
        "y_LIAR_train = pd.read_pickle('/content/NLP_final_project/FN-classification/Datasets_Processes/Train/y_LIAR_train.pkl')\n",
        "\n",
        "X_ISOT_test = pd.read_pickle('/content/NLP_final_project/FN-classification/Datasets_Processes/Test/X_ISOT_test.pkl')\n",
        "X_LIAR_test = pd.read_pickle('/content/NLP_final_project/FN-classification/Datasets_Processes/Test/X_LIAR_test.pkl')\n",
        "y_ISOT_test = pd.read_pickle('/content/NLP_final_project/FN-classification/Datasets_Processes/Test/y_ISOT_test.pkl')\n",
        "y_LIAR_test = pd.read_pickle('/content/NLP_final_project/FN-classification/Datasets_Processes/Test/y_LIAR_test.pkl')\n",
        "\n",
        "ISOT_train = pd.concat([X_ISOT_train, y_ISOT_train], axis=1)\n",
        "ISOT_test = pd.concat([X_ISOT_test, y_ISOT_test], axis=1)\n",
        "LIAR_train = pd.concat([X_LIAR_train, y_LIAR_train], axis=1)\n",
        "LIAR_test = pd.concat([X_LIAR_test, y_LIAR_test], axis=1)\n"
      ],
      "metadata": {
        "id": "VOH2W8-NTloZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ISOT_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Cj-f0JD2UZ1P",
        "outputId": "a3d59716-d515-4372-deb5-84802cffac4b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          title and text       subject  label\n",
              "22216  breaking gop chairman grassley ha enough deman...          news      0\n",
              "27917  failed gop candidate remembered hilarious mock...          news      0\n",
              "25007  mike penny new neighbor hilariously trolling h...          news      0\n",
              "1377   california pledge defend birth control insuran...  politicsnews      1\n",
              "32476  rancher living usmexico border destroy nancy p...      politics      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80a59422-fbeb-4f61-b5b7-d0f93314ced9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title and text</th>\n",
              "      <th>subject</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22216</th>\n",
              "      <td>breaking gop chairman grassley ha enough deman...</td>\n",
              "      <td>news</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27917</th>\n",
              "      <td>failed gop candidate remembered hilarious mock...</td>\n",
              "      <td>news</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25007</th>\n",
              "      <td>mike penny new neighbor hilariously trolling h...</td>\n",
              "      <td>news</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1377</th>\n",
              "      <td>california pledge defend birth control insuran...</td>\n",
              "      <td>politicsnews</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32476</th>\n",
              "      <td>rancher living usmexico border destroy nancy p...</td>\n",
              "      <td>politics</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80a59422-fbeb-4f61-b5b7-d0f93314ced9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-80a59422-fbeb-4f61-b5b7-d0f93314ced9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-80a59422-fbeb-4f61-b5b7-d0f93314ced9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-328412bd-1c1f-4019-9352-51504e6582fb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-328412bd-1c1f-4019-9352-51504e6582fb')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-328412bd-1c1f-4019-9352-51504e6582fb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build finite dataset for training"
      ],
      "metadata": {
        "id": "JrmdksO8Udl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_DS(df1, df2):\n",
        "    combined_df = pd.concat([df1, df2], ignore_index=True)\n",
        "    train = combined_df.sample(frac=1).reset_index(drop=True)\n",
        "    train['text'] = train['subject'] + ' ' + train['title and text']\n",
        "    train.drop(['subject', 'title and text'], axis=1, inplace=True)\n",
        "    return train\n",
        "\n",
        "train = build_DS(ISOT_train, LIAR_train)\n",
        "test = build_DS(ISOT_test, LIAR_test)"
      ],
      "metadata": {
        "id": "QvELGHq8Ut-o"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "EtsDhWulX7rv",
        "outputId": "7930ce33-5e37-449f-c110-83e03ad4c2fd"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                               text\n",
              "0      1  politicsnews hesitation carson accepts trump o...\n",
              "1      1  baseball corporation economy statefinances vot...\n",
              "2      0  leftnews mic drop lady approached sheriff clar...\n",
              "3      0  debt federalbudget messagemachine votingrecord...\n",
              "4      0  news tennessee republican pas bill make bible ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2165a766-47db-4506-9c75-ecab4436c20e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>politicsnews hesitation carson accepts trump o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>baseball corporation economy statefinances vot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>leftnews mic drop lady approached sheriff clar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>debt federalbudget messagemachine votingrecord...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>news tennessee republican pas bill make bible ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2165a766-47db-4506-9c75-ecab4436c20e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2165a766-47db-4506-9c75-ecab4436c20e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2165a766-47db-4506-9c75-ecab4436c20e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b3850fb3-c263-4e84-9029-fb0b057d25b5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b3850fb3-c263-4e84-9029-fb0b057d25b5')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b3850fb3-c263-4e84-9029-fb0b057d25b5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare dataloaders"
      ],
      "metadata": {
        "id": "EQ838dIAhiZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 42\n",
        "MAX_LENGTH = 256\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "5bfIhz17fzzm"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_instances(df, sample_size, seed):\n",
        "    return df.sample(n=sample_size, random_state=seed)\n",
        "\n",
        "# Constant parameters\n",
        "MINI_SAMPLE = 500\n",
        "SMALL_SAMPLE = 5000\n",
        "MEDIUM_SAMPLE = 15000\n",
        "LARGE_SAMPLE = 30000\n",
        "\n",
        "# Ask user if they want to reduce training set size\n",
        "inp = input(\"Do you want to reduce the training set size? (y/n) -> \")\n",
        "\n",
        "if inp.lower() == 'y':\n",
        "    inp2 = input(\"Choose size from the following options:\\n\"\n",
        "                    f\"1 - Mini Sample ({MINI_SAMPLE})\\n\"\n",
        "                    f\"2 - Small Sample ({SMALL_SAMPLE})\\n\"\n",
        "                    f\"3 - Medium Sample ({MEDIUM_SAMPLE})\\n\"\n",
        "                    f\"4 - Large Sample ({LARGE_SAMPLE})\\n\"\n",
        "                    \"Enter the number of your choice -> \")\n",
        "\n",
        "    # Choose the sample size based on user input\n",
        "    if inp2 == '1':\n",
        "        sample_size = MINI_SAMPLE\n",
        "    elif inp2 == '2':\n",
        "        sample_size = SMALL_SAMPLE\n",
        "    elif inp2 == '3':\n",
        "        sample_size = MEDIUM_SAMPLE\n",
        "    elif inp2 == '4':\n",
        "        sample_size = LARGE_SAMPLE\n",
        "    else:\n",
        "        print(\"Invalid choice. Using the default sample size.\")\n",
        "        sample_size = MEDIUM_SAMPLE\n",
        "\n",
        "    # Reduce the training set size\n",
        "    reduced_train = reduce_instances(train, sample_size, RANDOM_SEED)\n",
        "    print(f\"Training set size reduced to {sample_size} instances.\")\n",
        "\n",
        "    # Now you can use 'reduced_train' for further processing\n",
        "elif inp.lower() == 'n':\n",
        "    print(\"Training set size will not be reduced.\")\n",
        "else:\n",
        "    print(\"Invalid input. Training set size will not be reduced.\")"
      ],
      "metadata": {
        "id": "weUqefSFhqQL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a39cdfbf-fc59-462a-ab66-6a9b84e8ad62"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Do you want to reduce the training set size? (y/n) -> n\n",
            "Training set size will not be reduced.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Validation split\n",
        "train_text, val_text, train_labels, val_labels = train_test_split(train['text'], train['label'],\n",
        "                                                                    random_state=RANDOM_SEED,\n",
        "                                                                    test_size=0.25,\n",
        "                                                                    stratify=train['label'])\n",
        "test_text = test['text']\n",
        "test_labels = test['label']"
      ],
      "metadata": {
        "id": "QewxOld4iLuL"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train size:',train_text.shape[0])\n",
        "print('Val size:',val_text.shape[0])\n",
        "print('Test size:',test_text.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wW5rsHWChCRl",
        "outputId": "d3691f5b-40de-41bc-f820-5ec3d90a1995"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 34611\n",
            "Val size: 11538\n",
            "Test size: 11538\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "batch_size = BATCH_SIZE\n",
        "\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = MAX_LENGTH,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = MAX_LENGTH,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = MAX_LENGTH,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# Convert lists to tensors\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())\n",
        "\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)    # wrap tensors\n",
        "train_sampler = RandomSampler(train_data)                     # sampler for sampling the data during training\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "                                                              # dataLoader for train set\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)            # wrap tensors\n",
        "val_sampler = SequentialSampler(val_data)                     # sampler for sampling the data during training\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n",
        "                                                              # dataLoader for validation set"
      ],
      "metadata": {
        "id": "qEMiTAeOiacD"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freezing the parameters and defining trainable BERT structure\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False    # false here means gradient need not be computed"
      ],
      "metadata": {
        "id": "RnDvrDCEjNhp"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "    def __init__(self, bert, num_classes=2, hidden_size=768 , dropout_prob=0.1):\n",
        "      super(BERT_Arch, self).__init__()\n",
        "      self.bert = bert\n",
        "      self.dropout = nn.Dropout(dropout_prob)\n",
        "      self.relu =  nn.ReLU()\n",
        "      self.fc1 = nn.Linear(hidden_size,512)\n",
        "      self.fc2 = nn.Linear(512,num_classes)\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, sent_id, mask):\n",
        "      cls_hs = self.bert(sent_id, attention_mask=mask)['pooler_output']\n",
        "      x = self.fc1(cls_hs)\n",
        "      x = self.relu(x)\n",
        "      x = self.dropout(x)\n",
        "      x = self.fc2(x)\n",
        "      x = self.softmax(x)\n",
        "      return x\n",
        "\n",
        "model = BERT_Arch(bert)\n",
        "# Defining the hyperparameters (optimizer, weights of the classes and the epochs)\n",
        "optimizer = AdamW(model.parameters(),lr = 1e-5)\n",
        "cross_entropy  = nn.NLLLoss()\n",
        "epochs = 2"
      ],
      "metadata": {
        "id": "LpE292KUjSrM"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training process"
      ],
      "metadata": {
        "id": "V38Z2pzxjdak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining training and evaluation functions\n",
        "def train(model, train_dataloader):\n",
        "  model.train()\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "\n",
        "  for step,batch in enumerate(train_dataloader):                # iterate over batches\n",
        "    if step % 25 == 0 and not step == 0:                        # progress update after every 25 batches.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "    batch = [r for r in batch]                                  # push the batch to gpu\n",
        "    sent_id, mask, labels = batch\n",
        "    model.zero_grad()                                           # clear previously calculated gradients\n",
        "    preds = model(sent_id, mask)                                # get model predictions for current batch\n",
        "    loss = cross_entropy(preds, labels)                         # compute loss between actual & predicted values\n",
        "    total_loss = total_loss + loss.item()                       # add on to the total loss\n",
        "    loss.backward()                                             # backward pass to calculate the gradients\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)     # clip gradients to 1.0. It helps in preventing exploding gradient problem\n",
        "    optimizer.step()                                            # update parameters\n",
        "    preds=preds.detach().cpu().numpy()                          # model predictions are stored on GPU. So, push it to CPU\n",
        "\n",
        "  avg_loss = total_loss / len(train_dataloader)                 # compute training loss of the epoch\n",
        "                                                                # reshape predictions in form of (# samples, # classes)\n",
        "  return avg_loss                                 # returns the loss and predictions\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "  print(\"\\nEvaluating...\")\n",
        "  model.eval()                                    # Deactivate dropout layers\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  for step,batch in enumerate(val_dataloader):    # Iterate over batches\n",
        "    if step % 25 == 0 and not step == 0:          # Progress update every 25 batches.\n",
        "                                                  # Calculate elapsed time in minutes.\n",
        "                                                  # Elapsed = format_time(time.time() - t0)\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "                                                  # Report progress\n",
        "    batch = [t for t in batch]                    # Push the batch to GPU\n",
        "    sent_id, mask, labels = batch\n",
        "    with torch.no_grad():                         # Deactivate autograd\n",
        "      preds = model(sent_id, mask)                # Model predictions\n",
        "      loss = cross_entropy(preds,labels)          # Compute the validation loss between actual and predicted values\n",
        "      total_loss = total_loss + loss.item()\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "  avg_loss = total_loss / len(val_dataloader)         # compute the validation loss of the epoch\n",
        "  return avg_loss"
      ],
      "metadata": {
        "id": "Qez6Ddb7jfZk"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and predict\n",
        "best_valid_loss = float('inf')\n",
        "train_losses_no=[]                   # empty lists to store training and validation loss of each epoch\n",
        "valid_losses_no=[]\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    train_loss = train(model, train_dataloader)\n",
        "    valid_loss = evaluate(model, val_dataloader)\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'no_markers_model_weights.pt')\n",
        "    train_losses_no.append(train_loss)\n",
        "\n",
        "    pickle.dump(model, open('no_markers_model_weights.pkl','wb'))\n",
        "    pickle.load(open('no_markers_model_weights.pkl','rb'))\n",
        "\n",
        "    valid_losses_no.append(valid_loss)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mn36BGIejjmT",
        "outputId": "56fc72b9-c4d6-4c2e-81b9-c7bdfcb0972c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 2\n",
            "  Batch    25  of  1,001.\n",
            "  Batch    50  of  1,001.\n",
            "  Batch    75  of  1,001.\n",
            "  Batch   100  of  1,001.\n",
            "  Batch   125  of  1,001.\n",
            "  Batch   150  of  1,001.\n",
            "  Batch   175  of  1,001.\n",
            "  Batch   200  of  1,001.\n",
            "  Batch   225  of  1,001.\n",
            "  Batch   250  of  1,001.\n",
            "  Batch   275  of  1,001.\n",
            "  Batch   300  of  1,001.\n",
            "  Batch   325  of  1,001.\n",
            "  Batch   350  of  1,001.\n",
            "  Batch   375  of  1,001.\n",
            "  Batch   400  of  1,001.\n",
            "  Batch   425  of  1,001.\n",
            "  Batch   450  of  1,001.\n",
            "  Batch   475  of  1,001.\n",
            "  Batch   500  of  1,001.\n",
            "  Batch   525  of  1,001.\n",
            "  Batch   550  of  1,001.\n",
            "  Batch   575  of  1,001.\n",
            "  Batch   600  of  1,001.\n",
            "  Batch   625  of  1,001.\n",
            "  Batch   650  of  1,001.\n",
            "  Batch   675  of  1,001.\n",
            "  Batch   700  of  1,001.\n",
            "  Batch   725  of  1,001.\n",
            "  Batch   750  of  1,001.\n",
            "  Batch   775  of  1,001.\n",
            "  Batch   800  of  1,001.\n",
            "  Batch   825  of  1,001.\n",
            "  Batch   850  of  1,001.\n",
            "  Batch   875  of  1,001.\n",
            "  Batch   900  of  1,001.\n",
            "  Batch   925  of  1,001.\n",
            "  Batch   950  of  1,001.\n",
            "  Batch   975  of  1,001.\n",
            "  Batch 1,000  of  1,001.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    25  of    334.\n",
            "  Batch    50  of    334.\n",
            "  Batch    75  of    334.\n",
            "  Batch   100  of    334.\n",
            "  Batch   125  of    334.\n",
            "  Batch   150  of    334.\n",
            "  Batch   175  of    334.\n",
            "  Batch   200  of    334.\n",
            "  Batch   225  of    334.\n",
            "  Batch   250  of    334.\n",
            "  Batch   275  of    334.\n",
            "  Batch   300  of    334.\n",
            "  Batch   325  of    334.\n",
            "\n",
            "Training Loss: 0.552\n",
            "Validation Loss: 0.449\n",
            "\n",
            " Epoch 2 / 2\n",
            "  Batch    25  of  1,001.\n",
            "  Batch    50  of  1,001.\n",
            "  Batch    75  of  1,001.\n",
            "  Batch   100  of  1,001.\n",
            "  Batch   125  of  1,001.\n",
            "  Batch   150  of  1,001.\n",
            "  Batch   175  of  1,001.\n",
            "  Batch   200  of  1,001.\n",
            "  Batch   225  of  1,001.\n",
            "  Batch   250  of  1,001.\n",
            "  Batch   275  of  1,001.\n",
            "  Batch   300  of  1,001.\n",
            "  Batch   325  of  1,001.\n",
            "  Batch   350  of  1,001.\n",
            "  Batch   375  of  1,001.\n",
            "  Batch   400  of  1,001.\n",
            "  Batch   425  of  1,001.\n",
            "  Batch   450  of  1,001.\n",
            "  Batch   475  of  1,001.\n",
            "  Batch   500  of  1,001.\n",
            "  Batch   525  of  1,001.\n",
            "  Batch   550  of  1,001.\n",
            "  Batch   575  of  1,001.\n",
            "  Batch   600  of  1,001.\n",
            "  Batch   625  of  1,001.\n",
            "  Batch   650  of  1,001.\n",
            "  Batch   675  of  1,001.\n",
            "  Batch   700  of  1,001.\n",
            "  Batch   725  of  1,001.\n",
            "  Batch   750  of  1,001.\n",
            "  Batch   775  of  1,001.\n",
            "  Batch   800  of  1,001.\n",
            "  Batch   825  of  1,001.\n",
            "  Batch   850  of  1,001.\n",
            "  Batch   875  of  1,001.\n",
            "  Batch   900  of  1,001.\n",
            "  Batch   925  of  1,001.\n",
            "  Batch   950  of  1,001.\n",
            "  Batch   975  of  1,001.\n",
            "  Batch 1,000  of  1,001.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    25  of    334.\n",
            "  Batch    50  of    334.\n",
            "  Batch    75  of    334.\n",
            "  Batch   100  of    334.\n",
            "  Batch   125  of    334.\n",
            "  Batch   150  of    334.\n",
            "  Batch   175  of    334.\n",
            "  Batch   200  of    334.\n",
            "  Batch   225  of    334.\n",
            "  Batch   250  of    334.\n",
            "  Batch   275  of    334.\n",
            "  Batch   300  of    334.\n",
            "  Batch   325  of    334.\n",
            "\n",
            "Training Loss: 0.411\n",
            "Validation Loss: 0.358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving the model as a pkl file"
      ],
      "metadata": {
        "id": "3TiRPyEcnH6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/All-data-untagged-256.pkl'\n",
        "\n",
        "# Save the model using pickle\n",
        "with open(file_path, 'wb') as file:\n",
        "    pickle.dump(model, file)"
      ],
      "metadata": {
        "id": "DmudLzCmjwfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "EZMXcNHzlD0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load the model\n",
        "# file_path = '/content/drive/MyDrive/NLP-FINAL/All-data-untagged-256.pkl'\n",
        "# with open(file_path, 'rb') as file:\n",
        "#     model = pickle.load(file)"
      ],
      "metadata": {
        "id": "GRRW5z0YMlYt"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divide Testset to quarters because of \"Extra\" RAM usage (I'm colab pro...)\n",
        "quarter_size = len(test_seq) // 4\n",
        "\n",
        "# Split the test data and labels into quarters\n",
        "test_seq_1, test_seq_2, test_seq_3, test_seq_4 = np.split(test_seq, [quarter_size, quarter_size*2, quarter_size*3])\n",
        "test_mask_1, test_mask_2, test_mask_3, test_mask_4 = np.split(test_mask, [quarter_size, quarter_size*2, quarter_size*3])\n",
        "test_y_1, test_y_2, test_y_3, test_y_4 = np.split(test_y, [quarter_size, quarter_size*2, quarter_size*3])"
      ],
      "metadata": {
        "id": "Na7ETJRmZFBV"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_seq_parts = [test_seq_1, test_seq_2, test_seq_3, test_seq_4]\n",
        "test_mask_parts = [test_mask_1, test_mask_2, test_mask_3, test_mask_4]\n",
        "test_y_parts = [test_y_1, test_y_2, test_y_3, test_y_4]\n",
        "\n",
        "for test_seq_part, test_mask_part, test_y_part in zip(test_seq_parts, test_mask_parts, test_y_parts):\n",
        "    with torch.no_grad():\n",
        "        preds = model(test_seq_part, test_mask_part)\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "\n",
        "    preds = np.argmax(preds, axis=1)\n",
        "    print(\"Test Evaluation:\")\n",
        "    print(classification_report(test_y_part, preds))"
      ],
      "metadata": {
        "id": "RsB_10yqZsGW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "96ae2e06-4340-47ad-ca5e-75cac0509fb6"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-05e239b25f4a>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtest_seq_part\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mask_part\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_part\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_seq_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mask_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_parts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_seq_part\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mask_part\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-63-f7cf2864186b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_id, mask)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m       \u001b[0mcls_hs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pooler_output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_hs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1020\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m         )\n\u001b[0;32m-> 1022\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1023\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    610\u001b[0m                 )\n\u001b[1;32m    611\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    613\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    540\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}