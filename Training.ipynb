{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNNmucxF7BGIFZFXketA8mp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BabeRush/NLP_final_project/blob/main/Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "Wb80KGrq4u2h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notebook preparation"
      ],
      "metadata": {
        "id": "S5o-iTkq4zLE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configurations"
      ],
      "metadata": {
        "id": "DWmudSpX6gv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking high RAM from google\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atwulLF86qMV",
        "outputId": "dcb109d6-ab53-4011-9602-cfbe774e95a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning and checking for GPU usage\n",
        "import torch\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "DEVICE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IOrLnY3k8GbP",
        "outputId": "c5470441-1002-4a13-ae7b-3d8f89556d14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "jIx1EQ6r8bxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports & Installations"
      ],
      "metadata": {
        "id": "quzhpRQ769E7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers\n",
        "!pip install import-ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZxRBMFD4x9w",
        "outputId": "e4cfa56e-4856-4acb-cad2-27185d4df717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.32.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: import-ipynb in /usr/local/lib/python3.10/dist-packages (0.1.4)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.10/dist-packages (from import-ipynb) (7.34.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from import-ipynb) (5.9.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (0.19.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (4.8.0)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->import-ipynb) (2.18.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->import-ipynb) (4.19.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat->import-ipynb) (5.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->IPython->import-ipynb) (0.8.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.9.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->IPython->import-ipynb) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->import-ipynb) (0.2.6)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat->import-ipynb) (3.10.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTS\n",
        "# General\n",
        "import warnings\n",
        "import random\n",
        "import sys\n",
        "\n",
        "# Math & Data organization\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import pandas as pd\n",
        "import re\n",
        "import import_ipynb\n",
        "\n",
        "# Deep Learning\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast , BertForSequenceClassification\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AdamW\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Visualization\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from tabulate import tabulate\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Working with files\n",
        "from google.colab import files\n",
        "import pickle\n",
        "import shutil"
      ],
      "metadata": {
        "id": "Wb8Yc_8S5Be7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the datasets"
      ],
      "metadata": {
        "id": "FHXGntwn8tNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTIONAL - delete the cloned folder\n",
        "shutil.rmtree('/content/NLP_final_project')"
      ],
      "metadata": {
        "id": "kkbZXYK-SfeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the datasets\n",
        "# Description: ************TODO-LINK******************\n",
        "!git clone https://github.com/BabeRush/NLP_final_project.git\n",
        "shutil.move('/content/NLP_final_project/datasets_util.ipynb', '/content/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "wlwd4QMX8zJ7",
        "outputId": "a51bf59e-7d24-4a8d-f311-e2a59f4002ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NLP_final_project'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 54 (delta 21), reused 4 (delta 0), pack-reused 12\u001b[K\n",
            "Receiving objects: 100% (54/54), 41.42 MiB | 15.97 MiB/s, done.\n",
            "Resolving deltas: 100% (22/22), done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/datasets_util.ipynb'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_real = pd.read_csv('/content/NLP_final_project/True.csv',encoding='utf-8')\n",
        "df_fake = pd.read_csv ('/content/NLP_final_project/Fake.csv',encoding='utf-8')\n",
        "\n",
        "# reading these tsv files: seperated by tabs, no header\n",
        "liar_train = pd.read_csv('/content/NLP_final_project/train.tsv', sep='\\t',encoding='utf-8', header=None)\n",
        "liar_test = pd.read_csv('/content/NLP_final_project/test.tsv', sep='\\t',encoding='utf-8', header=None)\n",
        "liar_valid = pd.read_csv('/content/NLP_final_project/valid.tsv', sep='\\t',encoding='utf-8', header=None)\n",
        "\n",
        "# Rename the columns to match the 'df_real' dataset\n",
        "liar_train.columns = ['id', 'label', 'statement', 'subject', 'speaker', 'job_title', 'state_info', 'party_affiliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context']\n",
        "liar_valid.columns = ['id', 'label', 'statement', 'subject', 'speaker', 'job_title', 'state_info', 'party_affiliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context']\n",
        "liar_test.columns = ['id', 'label', 'statement', 'subject', 'speaker', 'job_title', 'state_info', 'party_affiliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context']"
      ],
      "metadata": {
        "id": "kahiL2ea8-Ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter missing values (statistics below)"
      ],
      "metadata": {
        "id": "GnLXkCWL9KBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_real = len(df_real)\n",
        "temp_fake = len(df_fake)\n",
        "temp_li_train = len(liar_train)\n",
        "temp_li_val = len(liar_valid)\n",
        "temp_li_test = len(liar_test)\n",
        "\n",
        "df_real = df_real.dropna()\n",
        "df_fake = df_fake.dropna()\n",
        "liar_train = liar_train.dropna()\n",
        "liar_valid = liar_valid.dropna()\n",
        "liar_test = liar_test.dropna()\n",
        "\n",
        "g1 = temp_real - len(df_real)\n",
        "g2 = temp_fake - len(df_fake)\n",
        "g3 = temp_li_train - len(liar_train)\n",
        "g4 = temp_li_val - len(liar_valid)\n",
        "g5 = temp_li_test - len(liar_test)\n",
        "\n",
        "print(f'Number of df_real sentences: {len(df_real)}, removed {g1}({(g1/temp_real)*100:.1f}%) instances')\n",
        "print(f'Number of df_fake sentences: {len(df_fake)}, removed {g2}({(g1/temp_fake)*100:.1f}%) instances')\n",
        "print(f'Number of liar_train sentences: {len(liar_train)}, removed {g3}({(g3/temp_li_train)*100:.1f}%) instances')\n",
        "print(f'Number of liar_valid sentences: {len(liar_valid)}, removed {g4}({(g4/temp_li_val)*100:.1f}%) instances')\n",
        "print(f'Number of liar_test sentences: {len(liar_test)} removed {g5}({(g5/temp_li_test)*100:.1f}%) instances')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2DB2tVa9W4c",
        "outputId": "d9153839-f39c-4f11-a1a4-e880d9199593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of df_real sentences: 21417, removed 0(0.0%) instances\n",
            "Number of df_fake sentences: 23481, removed 0(0.0%) instances\n",
            "Number of liar_train sentences: 6724, removed 3516(34.3%) instances\n",
            "Number of liar_valid sentences: 861, removed 423(32.9%) instances\n",
            "Number of liar_test sentences: 853 removed 414(32.7%) instances\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets combinations"
      ],
      "metadata": {
        "id": "keMewjkF-GeP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initial datasets"
      ],
      "metadata": {
        "id": "FLgXeHHADXBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print('Understanding \\\"df_real\\\" and \\\"df_fake\\\" columns:')\n",
        "# df_real.head()"
      ],
      "metadata": {
        "id": "89Mle0pNDgkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print('Understanding \\\"LIAR\\\" columns:')\n",
        "# liar_train.head()"
      ],
      "metadata": {
        "id": "Nnzu2GZ7D-I2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First DS"
      ],
      "metadata": {
        "id": "GzWAeTyFF8KY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets_util import prepare_dataset_1, prepare_dataset_2\n",
        "# Preparing the first DS\n",
        "# No markers:\n",
        "df_no_markers = prepare_dataset_1(df_real, df_fake, short_markers=False, text=True, title=False, subject=False)\n",
        "# Short markers:\n",
        "df_short_markers = prepare_dataset_1(df_real, df_fake, short_markers=True, text=True, title=False, subject=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjL6A4sL-JJ-",
        "outputId": "de837665-6412-40fc-a8a9-b798100a3b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "importing Jupyter notebook from datasets_util.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_no_markers.head()"
      ],
      "metadata": {
        "id": "_R365MCE93bp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "e24504d8-1d72-49c8-e9e0-c52613c3064c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     text_no_markers  label\n",
              "0  There s a petition on Change.org going around ...      0\n",
              "1  LONDON (Reuters) - Prime Minister Theresa May ...      1\n",
              "2  Hollywood actor James Woods tweeted about Trum...      0\n",
              "3  (Reuters) - A Turkish-Iranian gold trader on T...      1\n",
              "4  WASHINGTON/MARRAKESH, Morocco (Reuters) - Pres...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c5c6260c-cbac-4acc-9fef-38fcb51ea717\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_no_markers</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>There s a petition on Change.org going around ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LONDON (Reuters) - Prime Minister Theresa May ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hollywood actor James Woods tweeted about Trum...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(Reuters) - A Turkish-Iranian gold trader on T...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>WASHINGTON/MARRAKESH, Morocco (Reuters) - Pres...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5c6260c-cbac-4acc-9fef-38fcb51ea717')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c5c6260c-cbac-4acc-9fef-38fcb51ea717 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c5c6260c-cbac-4acc-9fef-38fcb51ea717');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-548acf2d-d81d-492e-95e0-b60a3d7fb28f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-548acf2d-d81d-492e-95e0-b60a3d7fb28f')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-548acf2d-d81d-492e-95e0-b60a3d7fb28f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Second DS"
      ],
      "metadata": {
        "id": "C9JGF4G8ZtlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Only no marker option\n",
        "df_no_markers_LIAR = prepare_dataset_2(liar_train, liar_valid, liar_test, subject=False, statement=True, speaker=True, context=False)"
      ],
      "metadata": {
        "id": "XdfLPDSKYatl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_no_markers_LIAR.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fEPOmFfzeKQ5",
        "outputId": "800761b1-6a36-4303-edb6-7ca6afb3e2c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     text_no_markers  label\n",
              "0  According to the nonpartisan Congressional Bud...      0\n",
              "1  99.97 percent of the kids live in poverty that...      0\n",
              "2  Our men and women of the Guard have been force...      0\n",
              "3  Says people in Africa literally walk two and t...      0\n",
              "4  Ronald Reagan banned ownership of fully automa...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78a36ffc-d403-48cc-b906-21dcec05751b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_no_markers</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>According to the nonpartisan Congressional Bud...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>99.97 percent of the kids live in poverty that...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Our men and women of the Guard have been force...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Says people in Africa literally walk two and t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ronald Reagan banned ownership of fully automa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78a36ffc-d403-48cc-b906-21dcec05751b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-78a36ffc-d403-48cc-b906-21dcec05751b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-78a36ffc-d403-48cc-b906-21dcec05751b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-72e77c1c-7b28-4946-b5fd-11dcf12bd7c2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-72e77c1c-7b28-4946-b5fd-11dcf12bd7c2')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-72e77c1c-7b28-4946-b5fd-11dcf12bd7c2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comb_df_no_markers = pd.concat([df_no_markers, df_no_markers_LIAR], ignore_index=True)"
      ],
      "metadata": {
        "id": "D5MPTql5giuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare dataloaders"
      ],
      "metadata": {
        "id": "EQ838dIAhiZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Constant parameters\n",
        "RANDOM_SEED = 42\n",
        "MAX_LENGTH = 256\n",
        "BATCH_SIZE = 32\n",
        "MINI_SAMPLE = 500\n",
        "SMALL_SAMPLE = 5000\n",
        "MEDIUM_SAMPLE = 15000\n",
        "LARGE_SAMPLE = 30000"
      ],
      "metadata": {
        "id": "5y2Rbh6uhNKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def reduce_instances(df, sample_size, seed):\n",
        "#   return df.sample(n=sample_size, random_state=seed)\n",
        "\n",
        "# temp_shape_no = comb_df_no_markers.shape\n",
        "# # NOTE the sample size\n",
        "# combined_df_no_markers = reduce_instances(comb_df_no_markers, LARGE_SAMPLE, RANDOM_SEED)\n",
        "# combined_df_no_markers.shape"
      ],
      "metadata": {
        "id": "weUqefSFhqQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df_no_markers = comb_df_no_markers"
      ],
      "metadata": {
        "id": "reHR_P1UGjo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Temp split\n",
        "train_text_no_markers, temp_text_no_markers, train_labels_no_markers, temp_labels_no_markers = train_test_split(combined_df_no_markers['text_no_markers'], combined_df_no_markers['label'],\n",
        "                                                                    random_state=RANDOM_SEED,\n",
        "                                                                    test_size=0.4,\n",
        "                                                                    stratify=combined_df_no_markers['label'])\n",
        "# Validation-Test split\n",
        "val_text_no_markers, test_text_no_markers, val_labels_no_markers, test_labels_no_markers = train_test_split(temp_text_no_markers, temp_labels_no_markers,\n",
        "                                                                random_state=RANDOM_SEED,\n",
        "                                                                test_size=0.5,\n",
        "                                                                stratify=temp_labels_no_markers)"
      ],
      "metadata": {
        "id": "QewxOld4iLuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "batch_size = BATCH_SIZE\n",
        "\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text_no_markers.tolist(),\n",
        "    max_length = MAX_LENGTH,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text_no_markers.tolist(),\n",
        "    max_length = MAX_LENGTH,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text_no_markers.tolist(),\n",
        "    max_length = MAX_LENGTH,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# Convert lists to tensors\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels_no_markers.tolist())\n",
        "\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels_no_markers.tolist())\n",
        "\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels_no_markers.tolist())\n",
        "\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)    # wrap tensors\n",
        "train_sampler = RandomSampler(train_data)                     # sampler for sampling the data during training\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "                                                              # dataLoader for train set\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)            # wrap tensors\n",
        "val_sampler = SequentialSampler(val_data)                     # sampler for sampling the data during training\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n",
        "                                                              # dataLoader for validation set"
      ],
      "metadata": {
        "id": "qEMiTAeOiacD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freezing the parameters and defining trainable BERT structure\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False    # false here means gradient need not be computed"
      ],
      "metadata": {
        "id": "RnDvrDCEjNhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "    def __init__(self, bert, num_classes=2, hidden_size=768 , dropout_prob=0.1):\n",
        "      super(BERT_Arch, self).__init__()\n",
        "      self.bert = bert\n",
        "      self.dropout = nn.Dropout(dropout_prob)\n",
        "      self.relu =  nn.ReLU()\n",
        "      self.fc1 = nn.Linear(hidden_size,512)\n",
        "      self.fc2 = nn.Linear(512,num_classes)\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, sent_id, mask):\n",
        "      cls_hs = self.bert(sent_id, attention_mask=mask)['pooler_output']\n",
        "      x = self.fc1(cls_hs)\n",
        "      x = self.relu(x)\n",
        "      x = self.dropout(x)\n",
        "      x = self.fc2(x)\n",
        "      x = self.softmax(x)\n",
        "      return x\n",
        "\n",
        "model = BERT_Arch(bert)\n",
        "# Defining the hyperparameters (optimizer, weights of the classes and the epochs)\n",
        "optimizer = AdamW(model.parameters(),lr = 1e-5)\n",
        "cross_entropy  = nn.NLLLoss()\n",
        "epochs = 2"
      ],
      "metadata": {
        "id": "LpE292KUjSrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training process"
      ],
      "metadata": {
        "id": "V38Z2pzxjdak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining training and evaluation functions\n",
        "def train(model, train_dataloader):\n",
        "  model.train()\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "\n",
        "  for step,batch in enumerate(train_dataloader):                # iterate over batches\n",
        "    if step % 25 == 0 and not step == 0:                        # progress update after every 25 batches.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "    batch = [r for r in batch]                                  # push the batch to gpu\n",
        "    sent_id, mask, labels = batch\n",
        "    model.zero_grad()                                           # clear previously calculated gradients\n",
        "    preds = model(sent_id, mask)                                # get model predictions for current batch\n",
        "    loss = cross_entropy(preds, labels)                         # compute loss between actual & predicted values\n",
        "    total_loss = total_loss + loss.item()                       # add on to the total loss\n",
        "    loss.backward()                                             # backward pass to calculate the gradients\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)     # clip gradients to 1.0. It helps in preventing exploding gradient problem\n",
        "    optimizer.step()                                            # update parameters\n",
        "    preds=preds.detach().cpu().numpy()                          # model predictions are stored on GPU. So, push it to CPU\n",
        "\n",
        "  avg_loss = total_loss / len(train_dataloader)                 # compute training loss of the epoch\n",
        "                                                                # reshape predictions in form of (# samples, # classes)\n",
        "  return avg_loss                                 # returns the loss and predictions\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "  print(\"\\nEvaluating...\")\n",
        "  model.eval()                                    # Deactivate dropout layers\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  for step,batch in enumerate(val_dataloader):    # Iterate over batches\n",
        "    if step % 25 == 0 and not step == 0:          # Progress update every 25 batches.\n",
        "                                                  # Calculate elapsed time in minutes.\n",
        "                                                  # Elapsed = format_time(time.time() - t0)\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "                                                  # Report progress\n",
        "    batch = [t for t in batch]                    # Push the batch to GPU\n",
        "    sent_id, mask, labels = batch\n",
        "    with torch.no_grad():                         # Deactivate autograd\n",
        "      preds = model(sent_id, mask)                # Model predictions\n",
        "      loss = cross_entropy(preds,labels)          # Compute the validation loss between actual and predicted values\n",
        "      total_loss = total_loss + loss.item()\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "  avg_loss = total_loss / len(val_dataloader)         # compute the validation loss of the epoch\n",
        "  return avg_loss"
      ],
      "metadata": {
        "id": "Qez6Ddb7jfZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and predict\n",
        "best_valid_loss = float('inf')\n",
        "train_losses_no=[]                   # empty lists to store training and validation loss of each epoch\n",
        "valid_losses_no=[]\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    train_loss = train(model, train_dataloader)\n",
        "    valid_loss = evaluate(model, val_dataloader)\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'no_markers_model_weights.pt')\n",
        "    train_losses_no.append(train_loss)\n",
        "\n",
        "    pickle.dump(model, open('no_markers_model_weights.pkl','wb'))\n",
        "    pickle.load(open('no_markers_model_weights.pkl','rb'))\n",
        "\n",
        "    valid_losses_no.append(valid_loss)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mn36BGIejjmT",
        "outputId": "56fc72b9-c4d6-4c2e-81b9-c7bdfcb0972c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 2\n",
            "  Batch    25  of  1,001.\n",
            "  Batch    50  of  1,001.\n",
            "  Batch    75  of  1,001.\n",
            "  Batch   100  of  1,001.\n",
            "  Batch   125  of  1,001.\n",
            "  Batch   150  of  1,001.\n",
            "  Batch   175  of  1,001.\n",
            "  Batch   200  of  1,001.\n",
            "  Batch   225  of  1,001.\n",
            "  Batch   250  of  1,001.\n",
            "  Batch   275  of  1,001.\n",
            "  Batch   300  of  1,001.\n",
            "  Batch   325  of  1,001.\n",
            "  Batch   350  of  1,001.\n",
            "  Batch   375  of  1,001.\n",
            "  Batch   400  of  1,001.\n",
            "  Batch   425  of  1,001.\n",
            "  Batch   450  of  1,001.\n",
            "  Batch   475  of  1,001.\n",
            "  Batch   500  of  1,001.\n",
            "  Batch   525  of  1,001.\n",
            "  Batch   550  of  1,001.\n",
            "  Batch   575  of  1,001.\n",
            "  Batch   600  of  1,001.\n",
            "  Batch   625  of  1,001.\n",
            "  Batch   650  of  1,001.\n",
            "  Batch   675  of  1,001.\n",
            "  Batch   700  of  1,001.\n",
            "  Batch   725  of  1,001.\n",
            "  Batch   750  of  1,001.\n",
            "  Batch   775  of  1,001.\n",
            "  Batch   800  of  1,001.\n",
            "  Batch   825  of  1,001.\n",
            "  Batch   850  of  1,001.\n",
            "  Batch   875  of  1,001.\n",
            "  Batch   900  of  1,001.\n",
            "  Batch   925  of  1,001.\n",
            "  Batch   950  of  1,001.\n",
            "  Batch   975  of  1,001.\n",
            "  Batch 1,000  of  1,001.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    25  of    334.\n",
            "  Batch    50  of    334.\n",
            "  Batch    75  of    334.\n",
            "  Batch   100  of    334.\n",
            "  Batch   125  of    334.\n",
            "  Batch   150  of    334.\n",
            "  Batch   175  of    334.\n",
            "  Batch   200  of    334.\n",
            "  Batch   225  of    334.\n",
            "  Batch   250  of    334.\n",
            "  Batch   275  of    334.\n",
            "  Batch   300  of    334.\n",
            "  Batch   325  of    334.\n",
            "\n",
            "Training Loss: 0.552\n",
            "Validation Loss: 0.449\n",
            "\n",
            " Epoch 2 / 2\n",
            "  Batch    25  of  1,001.\n",
            "  Batch    50  of  1,001.\n",
            "  Batch    75  of  1,001.\n",
            "  Batch   100  of  1,001.\n",
            "  Batch   125  of  1,001.\n",
            "  Batch   150  of  1,001.\n",
            "  Batch   175  of  1,001.\n",
            "  Batch   200  of  1,001.\n",
            "  Batch   225  of  1,001.\n",
            "  Batch   250  of  1,001.\n",
            "  Batch   275  of  1,001.\n",
            "  Batch   300  of  1,001.\n",
            "  Batch   325  of  1,001.\n",
            "  Batch   350  of  1,001.\n",
            "  Batch   375  of  1,001.\n",
            "  Batch   400  of  1,001.\n",
            "  Batch   425  of  1,001.\n",
            "  Batch   450  of  1,001.\n",
            "  Batch   475  of  1,001.\n",
            "  Batch   500  of  1,001.\n",
            "  Batch   525  of  1,001.\n",
            "  Batch   550  of  1,001.\n",
            "  Batch   575  of  1,001.\n",
            "  Batch   600  of  1,001.\n",
            "  Batch   625  of  1,001.\n",
            "  Batch   650  of  1,001.\n",
            "  Batch   675  of  1,001.\n",
            "  Batch   700  of  1,001.\n",
            "  Batch   725  of  1,001.\n",
            "  Batch   750  of  1,001.\n",
            "  Batch   775  of  1,001.\n",
            "  Batch   800  of  1,001.\n",
            "  Batch   825  of  1,001.\n",
            "  Batch   850  of  1,001.\n",
            "  Batch   875  of  1,001.\n",
            "  Batch   900  of  1,001.\n",
            "  Batch   925  of  1,001.\n",
            "  Batch   950  of  1,001.\n",
            "  Batch   975  of  1,001.\n",
            "  Batch 1,000  of  1,001.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    25  of    334.\n",
            "  Batch    50  of    334.\n",
            "  Batch    75  of    334.\n",
            "  Batch   100  of    334.\n",
            "  Batch   125  of    334.\n",
            "  Batch   150  of    334.\n",
            "  Batch   175  of    334.\n",
            "  Batch   200  of    334.\n",
            "  Batch   225  of    334.\n",
            "  Batch   250  of    334.\n",
            "  Batch   275  of    334.\n",
            "  Batch   300  of    334.\n",
            "  Batch   325  of    334.\n",
            "\n",
            "Training Loss: 0.411\n",
            "Validation Loss: 0.358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving the model as a pkl file - OPTIONAL"
      ],
      "metadata": {
        "id": "3TiRPyEcnH6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iewahZq8HZMD",
        "outputId": "711828bd-c4df-4bae-bf23-a673c75da4e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copy('/content/no_markers_model_weights.pkl', '/content/drive/MyDrive/NLP-FINAL/All-s_256-l')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3kiQyKogtq5S",
        "outputId": "8506fa96-7868-4273-cc7b-b0c8bdc4705d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/NLP-FINAL/All-s_256-l/no_markers_model_weights.pkl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "EZMXcNHzlD0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "file_path = '/content/drive/MyDrive/NLP-FINAL/All-s_256-l/no_markers_model_weights.pkl'\n",
        "with open(file_path, 'rb') as file:\n",
        "    model = pickle.load(file)"
      ],
      "metadata": {
        "id": "GRRW5z0YMlYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the midpoint index to split the tensors\n",
        "midpoint = len(test_seq) // 2\n",
        "\n",
        "# Split each tensor into two parts\n",
        "test_seq_1, test_seq_2 = np.split(test_seq, [midpoint])\n",
        "test_mask_1, test_mask_2 = np.split(test_mask, [midpoint])\n",
        "test_y_1, test_y_2 = np.split(test_y, [midpoint])"
      ],
      "metadata": {
        "id": "Na7ETJRmZFBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  preds = model(test_seq_1, test_mask_1)\n",
        "  preds = preds.detach().cpu().numpy()\n",
        "\n",
        "preds = np.argmax(preds, axis = 1)"
      ],
      "metadata": {
        "id": "RsB_10yqZsGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_y_1, preds))"
      ],
      "metadata": {
        "id": "kd5_q0dtZwmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  preds = model(test_seq_2, test_mask_2)\n",
        "  preds = preds.detach().cpu().numpy()\n",
        "\n",
        "preds = np.argmax(preds, axis = 1)"
      ],
      "metadata": {
        "id": "NhhE0WMkZy31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_y_2, preds))"
      ],
      "metadata": {
        "id": "cZQ0QtTWZzJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  preds = model(test_seq, test_mask)\n",
        "  preds = preds.detach().cpu().numpy()\n",
        "\n",
        "preds = np.argmax(preds, axis = 1)"
      ],
      "metadata": {
        "id": "zOkytJeUkzBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_y, preds))"
      ],
      "metadata": {
        "id": "Wk0lKNbalK5G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}